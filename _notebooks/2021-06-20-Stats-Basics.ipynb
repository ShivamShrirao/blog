{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540d1b70-24dd-4b33-b3aa-766da89fe88d",
   "metadata": {},
   "source": [
    "# Stats Basics\n",
    "> Just some basic stats concepts for quick revision.\n",
    "\n",
    "- toc: true \n",
    "- comments: true\n",
    "- hide: true\n",
    "- image: images/stats/high_bias.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a804d0a-2ea7-48a9-899a-64cc3403df5d",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "- Split the training data into multiple folds, eg. Four folds of 25% each.\n",
    "- For each fold as testing, and rest as training train a model each time.\n",
    "- Do same with different models. Choose the one which gets the most folds correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf4a49d-9287-45fc-bf33-34615a58843e",
   "metadata": {},
   "source": [
    "# Sensitivity & Specificity\n",
    "\n",
    "- **Sensitivity**: Percentage of positives correctly identified. (True Positive rate)\n",
    "    - Eg.: Percentage of patients correctly identified to have a disease among all actually having disease.\n",
    "    - Sensitivity = $\\frac{TP}{TP+FN}$\n",
    "\n",
    "\n",
    "- **Specificity**: Percentage of negatives correctly identified. (True Negative rate)\n",
    "    - Eg.: Percentage of patients correctly identified to NOT have a disease among all actually NOT having disease.\n",
    "    - Specificity = $\\frac{TN}{TN+FP}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5560d58-56ea-4852-9f2d-ff69a1811b2d",
   "metadata": {},
   "source": [
    "|                   | Real Has | Real Not Has |\n",
    "|-------------------|----------|--------------|\n",
    "| Predicted Has     |    TP    |      FP      |\n",
    "| Predicted Not Has | FN       | TN           |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd13584e-708c-44d5-bcc7-61c88e42aef0",
   "metadata": {},
   "source": [
    "# Precision & Recall\n",
    "\n",
    "- **Precision**: Proportion of positives correctly identified.\n",
    "    - Eg.: Number of patients actually having the disease among all prediicted to be having the disease.\n",
    "    - Precision = $\\frac{TP}{TP+FP}$\n",
    "\n",
    "\n",
    "- **Recall** = [Sensitivity](#Sensitivity-&-Specificity)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a5e532-847e-437b-8f80-16dd96eee009",
   "metadata": {},
   "source": [
    "# Bias & Variance\n",
    "\n",
    "- **Bias**: \"Prior assumptions\" in model/algorithm preventing it to fit on data.\n",
    "    - Eg: Linear regression will be a straight line so can't fit on curved data, therefore it has high bias and low variance.\n",
    "    ![](images/stats/high_bias.png \"https://youtu.be/EuBBz3bI-aA\")  \n",
    "        *Image Credit: [Machine Learning Fundamentals: Bias and Variance](https://youtu.be/EuBBz3bI-aA)*\n",
    "\n",
    "\n",
    "- **Variance**: Model/algorithm is can \"vary\" itself alot and thus can overfit on data.\n",
    "    - Eg: Lot of curves going exactly through all data points, model won't generalize, therefore it has high variance and low bias.\n",
    "    ![](images/stats/high_variance.png \"https://youtu.be/EuBBz3bI-aA\")  \n",
    "        *Image Credit: [Machine Learning Fundamentals: Bias and Variance](https://youtu.be/EuBBz3bI-aA)*\n",
    "\n",
    "\n",
    "- **Bias Variance Tradeoff**: We gotta find a good comprise among the two to find best model. \n",
    "\n",
    "\n",
    "**Intersting Fact**: Check out double descent in deep learning, highly over-parameterized models can at first overfit, perform worse but then start to perform better again.  \n",
    "An intuitive possible explanation: https://twitter.com/daniela_witten/status/1292293102103748609"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0c9512-8212-452d-b150-32abdabe7de3",
   "metadata": {},
   "source": [
    "# ROC & AUC\n",
    "\n",
    "- __Receiver Operator Characterstic (ROC)__: Plot True Positive Rate vs False Positive Rate of model for different classification thresholds.  \n",
    "    - Decide what works better for you, if you want classify positives more correctly and some false positives,\n",
    "    - OR lesser true positives for no false positives.  \n",
    "    ![](images/stats/roc.png \"https://youtu.be/4jRBRDbJemM\")  \n",
    "        *Image Credit: [ROC and AUC, Clearly Explained!](https://youtu.be/4jRBRDbJemM)*\n",
    "\n",
    "\n",
    "- __Area Under Curve (AUC)__: Compare ROC graphs.  \n",
    "    - Graph with higher area better.  \n",
    "    - False positive rate can often be replaced with Precision.  \n",
    "    ![](images/stats/auc.png \"https://youtu.be/4jRBRDbJemM\")  \n",
    "        *Image Credit: [ROC and AUC, Clearly Explained!](https://youtu.be/4jRBRDbJemM)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e10da93-6621-4616-a5f4-d54c44575768",
   "metadata": {},
   "source": [
    "# Residuals\n",
    "- __Residuals__ : Vertical distance of data point from line.\n",
    "- __R squared__ : $\\large1 -\\frac{\\text{Sum of squares of Residuals}}{\\text{Total sum of squares(variance)}}$.  \n",
    "0 -> Worst, 1 -> Best."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518b4918-48b6-411d-ab4c-c1803a275fbe",
   "metadata": {},
   "source": [
    "$log(odds) = log(\\frac{p}{1-p})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb6628-df36-45fe-a2b9-bedd2ad2146e",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Probability between 0 and 1.\n",
    "Convert to log(odds) on y axis to compare to linear regression.\n",
    "\n",
    "- __Uses Maximum Likelihood__: Log adds for datapoints converted to probability.  \n",
    "- __Log Likelihood__: Sum of logs of probabilities or multiplication of probabilities.  \n",
    "![](images/stats/logistic_likelihood.png \"https://youtu.be/BfKanl1aSG0\")  \n",
    "    *Image Credit: [Logistic Regression Details Pt 2: Maximum Likelihood](https://youtu.be/BfKanl1aSG0)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24540ad9-2440-4235-b15c-9f6357d953eb",
   "metadata": {},
   "source": [
    "# Ridge (L2) Regularization\n",
    "\n",
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
